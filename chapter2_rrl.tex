\chapter{Review of Related Literature} \label{sec:rrl-title}
University course timetabling is a well-known problem. Many approaches has already been proposed before. These proposals usually use optimization-based algorithms. However, some approaches utilize some form of machine learning, specifically reinforcement learning, as part of their methodology. No single approach works best for all, and these approaches have their own tradeoffs.

\section{Great Deluge-Based Works}
Many previous works dealing with course timetabling utilize an optimizing heuristic (or derivatives of it) called \textbf{Great Deluge}. Great Deluge was introduced by Gunter Dueck, and is a heuristic that is similar to Hill Climbing and Simulated Annealing. To understand how it works, imagine that you are in a point in some area with mountainous terrain. This area constitutes your solution space, with higher points in the area having higher values and, thus, having a better solution. The initial point you are located in in the area represents the initial solution that is generated. Imagine as well that it is raining endlessly and the water level $W$ is continuously rising at a constant rate $R_{w}$, where $R_{w}$. $W$ can start at any value that is greater than $0$. Assuming that we are attempting to maximize some function $Q$, which evaluates a solution based on some criteria, your goal is to locate the relatively highest point in the location. This point can be thought of as the local optimum. Locating the highest point involves walking around the area that is not below the current water level. This will force you to walk to a higher and higher point since $W$ is constantly rising. Once you are no longer able to proceed to a higher level, it means that you are now in a local optimum. Going outside the analogy and back to a technical perspective, this local optimum would now be the \textit{relatively} best solution for your problem. Every "walk" or move to a higher point is nuanced relative to the analogy. A single walk means construction of a new solution $S_{new}$ with basis on the current solution $S_{current}$. If $Q(S_{new}) \geq W$ \cite{gd-burke}, then we accept $S_{new}$ as the new current solution and "walk" towards it, and we increase $W$ by $R_{w}$. Otherwise, we simply generate a new $S_{new}$. These walks are performed until $Q(S_{new})$ is not greater than $Q(S_{curr})$ for a long time or we have reached the maximum number of moves/iterations \cite{intro-gd-dueck}. Great Deluge can also be adapted to minimize $Q$. Instead of $W$ increasing, it will be decreasing by the same rate. A solution $S$ will now be accepted if $Q(S) \leq W$. Conversely, the algorithm will stop when $Q(S_{new})$ is not lesser than $Q(S_{curr})$. The second stopping condition for the algorithm still applies in this case \cite{gd-burke}\cite{nlgd-landa-silva}\cite{nlgdrl-obit}. This minimization case is the one adapted by Great Deluge-based works that focus on course timetabling.

One of the earliest works that uses Great Deluge was that of Burke, E., Bykov, Y., Newall, J., and Petrovic, S. \cite{gd-burke}. Their work explores the use of Great Deluge in university course timetabling. In their work, they defined $Q$ as the sum of the number of soft constraints violated. They also, however, slightly modified Great Deluge. We will be referring to the modified version as the Extended Great Deluge (EGD). Instead of simply obtaining a single new solution $S$ in an iteration and comparing $Q(S)$ to $W$. Burke, E., et. al. extended Great Deluge to take multiple neighbouring solutions $N$ on every iteration. A random solution $S_{N}$ from $N$ will be taken and it will be the one to be compared to $W$ and the current solution. $S_{N}$ will be accepted as the current solution if $Q(S_{N}) \leq Q(S_{curr})$. $S_{N}$ can still be accepted only under the condition that $Q(S_{N}) \leq W$. In addition to taking multiple solutions in an iteration, a few more extensions have been added to Great Deluge by Burke, et. al.. The initial value for $W$ is set to $Q(S_{i})$, where $S_{i}$ is the initial solution. Computing for $R_{w}$ is made easier by using the following equation:

\[
    R_{w} = \frac{W - Q(S^{'})}{N_{moves}}
\]

$N_{moves}$ denotes the number of moves the algorithm will perform before terminating. The desired number of violations the desired solution $S^{'}$ should have is denoted by $Q(S^{'})$. Through their work, Burke, E., et. al. observed that there is a tradeoff between the quality of produced timetables and the amount of searching time given to the algorithm. The authors noted that even though in some situations, a user would require obtaining the results quickly, it is naturally more preferable that one gives the algorithm more in order for it provide high quality timetables. As the authors have mentioned, course timetabling normally only occurs once or twice in a year. Thus, a long amount of time for searching "seems to be quite acceptable". EGD was compared to Simulated Annealing (SA), Threshold Acceptance (TA), Hill-Climbing (HC), and 21 algorithms submitted for the International Timetabling Competition (ITC) of 2002. The data set used for comparing the algorithms was the one provided by the aforementioned competition The experiments of Burke, E., et. al. show that EGD produce less scattered results than SA, TA, and HC. This proves the effectiveness of EGD as a heuristic for course timetabling. Further proof of this effectiveness is shown by comparing the heuristic to the 21 other algorithms participating in the ITC. EGD generated the best results for 8 out of 23 data sets among the participating algorithms \cite{gd-burke}.

Building upon the work of Burke, et. al. is that of Landa-Silva, D., and Obit, J.'s \cite{nlgd-landa-silva}. The primary contribution of Landa-Silva, D., and Obit, J. is the introduction of a modification of the Extended Great Deluge by Burke, E., et. al., the Non-Linear Great Deluge. Key to this heuristic is the use of an equation, instead of a constant rate, in determining the amount of reduction in the water level in an iteration. We refer to this amount as the decay rate. The next water level $W$ is computed with the following equation:

\[
	W = W \times (exp^{-\delta(rand[min, max])}) + P	
\]

$P$ is "the minimum expected penalty corresponding to the best solution". Another key part of the equation is $exp^{-\delta(rand[min, max])}$, which controls the speed the water level decreases. Besides from contributing an equation-based decay rate for the water level, another modification they added to the Extended Great Deluge is the conditional increase of the water level. If the current solution obtained $S_{curr}$ is about to converge with the water level $W$, i.e. when $W - Q(S_{curr}) < 1$, then the Non-Linear Great Deluge algorithm allows the water level to rise for a certain amount. This amount is a random value from the interval $[W_{min}, W_{max}]$. The intended increase is to allow the algorithm to "accept slightly worse solutions to explore different areas of the search space in the hopes of finding better solutions". The work of Landa-Silva, D. and Obit, J. uses three moves in generating solutions:

\begin{itemize}
	\item \textbf{M1}: Selects one random class and gives it a random but feasible timeslot-room pair.
	\item \textbf{M2}: Selects two random classes and swaps their timeslot-room pairs while maintaining feasibility.
	\item \textbf{M3}: Looks for a class which violates soft constraints based on their current timeslot-room pair. It then moves this class to a random timeslot-room pair but still maintaining feasibility.
\end{itemize}

It should be noted that these three neighbourhood moves always maintain compliance with the hard constraints. Another key modification the authors introduced is the three-step heuristic for generating an initial solution. This heuristic is based on the work by Chiarandini, M., Birattari, M., Socha, K., and Rossi-Doria, O. \cite{chiarandini-effective-hybrid}. The three steps are as follows:

\begin{enumerate}
	\item All classes will first be assigned a random timeslot. However, unassigned classes with the highest number of conflicts will be assigned first. A class has a conflict with another class if it has students also taking the other class. The maximum bipartite matching algorithm \cite{maximum-bipartite-matching} is then used to assign each event to a room. This first step of creating an initial timetable $S$ does not guarantee feasibility. But the solution will be further improved by the later steps.
	\item Moves M1 and M2 are then used to improve the current $S$. At this step, feasibility and satisfaction of the hard constraints are sought. As such, "a move is only accepted if it improves the satisfaction of the hard constraints". This step performed continuously until there are no more improvements to $S$ after 10 iterations.
	\item Tabu search \cite{brownlee-tabu-search} is then used to further refine $S$. In this step, classes that were assigned $t_{iter}$ iterations ago will be stored in the tabu list. $t_{iter}$ is computed as $t_{iter} = ran(10) + \delta \times N_{v}$, where $ran(10)$ is a random number from the interval $(0, 10)$, $\delta = 0.6$, and $N_{v}$ is the number of classes that partook in violating the hard constraints. The termination condition for this step is when after 500 iterations, no solution has been produced that is better than the current best.
\end{enumerate}

Only step 1 is run once. The other steps, steps 2 and 3, are performed repeatedly in order until a feasible solution/timetable is obtained. In all 11 experiment instances obtained from the work of Socha, K., Knowles, J., and Sampels, M. \cite{socha-maxmin-ant-system}, which has 5 small instances, 5 medium instances, and 1 large instance, Non-Linear Great Deluge produced results better than Great Deluge. Interestingly enough, in 4 of these experiment cases, NLGD performed the best compared to the best known literature at the time NLGD was introduced \cite{nlgd-landa-silva}.

\section{Machine Learning-Based Works}
All related works encountered that use machine learning that were proposed do not use a purely machine-based approach. Rather, they combine heuristics with machine learning.

An example of such works, is that of Obit, J., Landa-Silva, D., Sevaux, M., and Ouelhadj, D. \cite{nlgdrl-obit}. Their work is built upon their previous work on Non-Linear Great Deluge for course timetabling \cite{nlgd-landa-silva}. An addition to their work compared to previous studies is the use of reinforcement learning as part of their solution generation process. Previous works, relative to their's, randomly select moves. But, Obit, J., et. al. uses reinforcement learning to determine which moves is best to further refine the current solution. Two types of reinforcement learning are employed and investigated in their work: \textbf{(a)} reinforcement learning with static memory length, and \textbf{(b)} reinforcement learning with dynamic memory length. Initially, all moves are given equal weights of $0.01$, with the weight for each move $i$ denoted by $w_{i}$ and thus, equal probabilities of being chosen for an iteration. The probability for each move is denoted by $p_{i}$ is computed by

\[
	p_{i} = \frac{w_{i}}{\sum_{i=1}^{n}w_{i}}
\]

$n$ is the number of moves there are. In the type with static memory length, on every iteration, the moves are punished or rewarded depending on their performance. A move is rewarded by giving its weight 1 point. It is punished by giving it no points at all. The weights are updated every learning period $lp$ computed using $lp = max(N_{moves}/500, n)$, where the total number of feasible moves performed is denoted by $N_{moves}$. During this learning period, the water level is also increased by a certain amount. Performance of each move is computed based on the number of it was called, number of times it generates solutions that has different fitness values, and the number of times it produces solutions that have been accepted. On the other hand, reinforcement learning (RL) with dynamic memory length, the probability $p_{i}$ of a move being chosen is computed through

\[
	p_{i} = \frac{w_{i} + w_{min}}{\sum_{i=1}^{n}{w_{i} + w_{min}}}
\]

In this equation, $w_{min} = min(0, w_{i})$. Unlike its counterpart, this type of RL updates the weights of the moves every time a feasible move is performed. The performed move is rewarded when it produces an improve solution, and punished otherwise. Differing from its counterpart once again, this type of RL uses a piecewise function $R$ to compute the reward/punishment for the currently selected move $i$ at the current iteration $j$. In the function, $\Delta$ is the difference between the best solution so far and the current generated solution.

\[
	R = 
	\begin{cases}
	1 & \text{if}\,\Delta < 0 \\
	-1 & \text{if}\,\Delta > 0 \\
	0.1 & \text{if}\,\Delta = 0\,\text{and new solution} \\
	-0.1 & \text{if}\,\Delta = 0\,\text{and no new solution} \\
	\end{cases}
\]

Each weight $w_{i}$ is then computed at each iteration $h$ with the formula below

\[
	w_{i} = \sum_{j = n_{timeslots}}^{h} \sigma^{j}R
\]

$n_{timeslots}$ is the number of timeslots there are. The parameter $\sigma$ is a random value between $(0.5, 1.0]$. The parameter's value is set every learning period $lp$. Similar to the previous type of RL, the $lp$ is still determined using the same formula, and the water level increases on every learning period. The experiments of this work included an experiment comparing the two types of reinforcement learning employed. Both types of RL produced optimal results in the small problem instances and good results in the medium instances. In the large problem instance, the static memory RL produced a better result than its counterpart. When comparing to other Great Deluge-based works, namely EGD, NLGD, ENLGD, and GD, the static memory RL produced the best solution in all problem instances except the large instance, in which its solution's score has a difference of only 1 from the best solution, which was generated by the Extended Great Deluge. The dynamic memory RL produced the worst solution among the algorithms compared for the large problem, but came in second overall in all of the medium problem instances, but one in which it came in third. When comparing the algorithm to hyper-heuristic-based algorithms with the same problem instances, the algorithm, specifically the static memory RL-based algorithm, produced the best results, except for the large instance. The authors also noted that the value of $lp$ affects the quality of the best solution the algorithm produces, with the sweet spot being either $lp = 2500$ or $lp = 5000$. When the algorithm is finally compared to course timetabling algorithms that are known to produce the best results for a specific problem instance, the algorithm, specifically the static memory RL one, produced new best solutions in all medium problem instances. This proves that the algorithm is a viable solution for course timetabling.

\section{Genetic Algorithm-Based Works}
Great Deluge is a metaheuristic \cite{intro-gd-dueck} that has been used for solving course timetabling problems \cite{gd-burke}\cite{nlgd-landa-silva}\cite{nlgdrl-obit}. Aside from Great Deluge, another metaheuristic that has seen use in the course timetabling problem and its variations is the Genetic Algorithm. The genetic algorithm is an optimization algorithm whose behaviour is based on how nature works, particularly on how reproduction works at a genetic level. Many implementations of the genetic algorithm for course timetabling represents the problem by having each gene in the genetic representation of the timetabling be a two-element tuple which consists of the class and the agents that will partake in that said class \cite{alves-novel-recursive}\cite{raghavjee-ga-south-africa}\cite{supachate-noval-approach-ga-thai}. Some use another representation. In the algorithm, an initial population is first generated. This population does not necessarily contain the locally optimal solution but it is where the relatively best solution will be obtained from. This initial population is referred to as the first generation. From this population, a certain number of individuals will be randomly selected to be bred with one another and be the parents of the next generation. Selection of individuals is dependent on an individual's fitness, with the most fit individuals usually being selected. Calculating this fitness is dependent on the problem. In the context of course timetabling, fitness is based on the constraints that have been violated by the current solution/timetable generated \cite{alves-novel-recursive}\cite{raghavjee-ga-south-africa}\cite{johan-ga-sa-comparison}\cite{yik-ga-timetabling}\cite{supachate-noval-approach-ga-thai}\cite{wutthipong-performance-study-genetic-operators}\cite{sanjay-an-application-of-ga}. The breeding process involves selection of parents and having genes from the parents crossover and/or mutate to produce new offspring. Crossover is when genes from both parents are combined to produce an offspring. On the other hand, mutation is done by changing a random gene from either parent to create an offspring. Determining which genes from either parent to apply onto the offspring and which to mutate is dependent on implementation. Once a population of new generations is established, the cycle repeats. This continuous reproduction of generations eventually produces solutions "moves" towards the optimal solution \cite{what-is-ga}. Despite being able to produce feasible solutions for university timetabling, it should be noted that using a genetic algorithm approach may require more time executing compared to other approaches due to its population-based property. When compared to simulated annealing, another approach for university timetabling, the genetic algorithm takes more time executing \cite{johan-ga-sa-comparison}. However, approaches utilizing the genetic algorithm can see an improvement in execution time when they utilize graphics processing units (GPUs). The work of Yousef, A., Salama, C., Jad, M., El-Gafy, T., Matar, M., and Habashi, S. showed that it is possible to speed up genetic algorithms using GPUs. In their work, they accelerated the computation of the fitness function. Their experiments show that execution speed can be improved by up to 59 times in very large problem instances and by 280\% overall when utilizing the GPU \cite{yousef-gpu-ga}. 

A work that utilizes genetic algorithms is the work of Alves, S., Oliveira, S., and Rocha Neto, A. \cite{alves-novel-recursive}. Unlike the previous works which tackles the problems as organizing a single set of lectures onto a table of time slots (which can be thought of timetabling for a semester), Alves. S., et. al.'s work organizes a timetable for entire courses throughout multiple semesters. We refer to a course here as a degree a student takes up in college. It is important to note that the perspective in which they tackle the problem is that of the Brazilian university academia's. Unique to their approach is that they only consider a single course in timetabling at a time. This means that the classes of other courses are not \textbf{directly} taken into account. Instead, what is considered is the unavailability of agents, which are students and professors. This unavailability determined from the assignments of the agents from the timetabling of the previous courses. Each course will contain timetables for each semester. In constructing the timetable for a course, a genetic algorithm is applied on each course, with each individual being a timetable for the course. Specific rules for selection of parents have not been specified in the paper but it can be presumed that the fittest individuals are chosen for breeding. Fitness $F$ is computed using the following function:

\[
	F(C) = 1 - \frac{AM_{C} + AU_{C} + AL_{C}}{AM_{wc} + AU_{wc} + AL_{wc}}
\]

$C$ is a course timetable. $AM$ represents the number of times an agent has been assigned to concurrent events. $AU$ stands for the number of times agents have assigned to classes whose timeslots they are not available in. Lastly, $AL$ represents the number of times a class has been given more than three consecutive timeslots. The numerator represents the values for $C$, while the denominator denotes the worst case values of those variables. Crossover is performed using the OX operator from the work of Chinnasri, W., Krootjohn, S., and Sureerattanan, N. \cite{wutthipong-performance-study-genetic-operators}. Mutation is performed in a course by selecting a random semester timetable and swapping two random timeslots. The timetable of a course is then stored in a global timetable. This timetabling is performed until all courses have been timetabled. The final solution is the global timetable. According to the experimental results, the approach of Alves, S., et. al. produces timetables that have a fitness close to $1$. However, producing fit timetables required performing the approach multiple times with different values. In their work, the authors obtained the the parameter values by performing 15 tests with each test having different values for the parameters. It should be highlighted that the stop criteria has been set to when a fitness of 1 has been achieved or the execution time has reached 10 minutes. Alves, S., et. al. found that, in their problem context, the parameters that produced the best results are: (a) 25\% mutation rate, (b) 50\% OX crossover rate, and (c) a population size of 75. Using these parameters, the authors managed to have their approach produce 493 generations and having a run time of just 3.7 minutes, with all timetables for each course having a fitness of approximately $1$.

Innet, S. has also utilized a genetic algorithm for timetabling in Thai universities, at least for the University of the Thai Chamber of Commerce \cite{supachate-noval-approach-ga-thai}. Unlike the other aforementioned works, the work of Innet, S. focuses on examination timetabling, instead of course timetabling. However, his approach may still be utilized for course timetabling as the former is similar with the latter
%((CITE PAPER THAT SAYS THAT EXAM TT IS SIMILAR TO C TT))
. The crossover operation that was chosen for Innet, S.'s work is a simple operation of selecting random genes from one parent and placing them unto a child chromosome in the same position as they were in the parent. This would entail that unfilled slots will be present. These slots will filled by all genes, except thse that have already been selected from the first parent, from the other parent with the first gene filling the first unfilled slot, the second with the second slot, and so on. The mutation operation is simpler. A parent will be selected and its genes will be copied onto a child. Two random genes will be selected and swapped. Crossover and mutation are not performed consecutively. Rather, one of them will be performed depending on the crossover probability parameter. During breeding for the next generation, only two individuals will be selected as the parent with the condition that these parents have the best fitness value. Basing the experimental, Innet, S.'s approach manages to produce fit timetables (only having a penalty cost of 32) but only when the crossover probability is set to 75\%. Unfortunately, his approach was not compared to other approaches from known literature. As such, it cannot be determined how well his approach performs compared to other approaches such as Great Deluge in examination timetabling, especially in the case he is applying his proposed approach \cite{supachate-noval-approach-ga-thai}.

Another genetic algorithm-based approach is that of Bedoya, C. F., and Santos, M. \cite{bedoya-non-standard-ga}. A key point to take note with the approach of the authors is that, unlike prevous works (especially the aforementioned ones), the crossover operation standard in genetic algorithms is not used. The reasoning behind this is that the operation can introduce violations to the hard constraints. This will necessitate the repairing any resulting timetables to satisfy the violated constraints. As such, only the mutation operation has been used. It was noted by the authors that a timetable already instrinsically has all the necessary information to produce a feasible timetable. Properly sorting this timetable is all that is required to produce a good timetable. Mixing the genes of two would-be parents will not improve the solution. The mutation operation proposed by Bedoya, C. F., and Santos, M. is not completely based upon randomness. Instead, a set of rows will be swapped with another set of rows. These rows are determined by two swapping points, where the slicing of the chromosome for swapping will start, and the depth parameter which determines how many rows will be swapping. Two random genes from the chromosome are selected as the swapping points for the mutation operation. The probability in which a co-beliigerent gene will be chosen as a swapping point is determined by a parameter. The fitness function $F$ in the work of Bedoya, C. F., and Santos, M. is defined as:

\[
	F_{obj} = \sum w{i}R{i}
\]

where $R_{i}$ represents the number of times a constraint was violated and is weighted by a value $w_{i}$, which represents the priority of the constraint. It must be noted that the authors' work seeks to maximize this fitness function. Each of the unsatisfied constraints gives a negative value, making the fitness for the optimal solution to be $0$. The experiments of Bedoya, C. F., and Santos, M. show that their non-standard genetic algorithm is capable of producing optimal timetables. It was also observed that increasing the population size reduces the number of iterations needed to produce the optimal solution. However, further increasing the population size beyond $20$ gives back diminishing returns especially on system resources expended. The number of iterations needed to obtain the optimal solutions stagnates and remains the same at around $250$ when going beyond that threshold point of $20$. However, in the same vein as the work of Innet, S. \cite{supachate-noval-approach-ga-thai}, the performance of the non-standard genetic algorithm cannot be determined since the authors did not conduct experiments to compare their approach against previous approaches for course timetabling \cite{bedoya-non-standard-ga}.

Course timetabling using a genetic algorithm procedure has also been performed in a non-university setting. Raghavjee, R. and Pillay, N. applied the genetic algorithm for a primary and high school in South Africa \cite{raghavjee-ga-south-africa}. Similar to the work of Bedoya, C. F., and Santos, M., the authors discarded the crossover operation and only used the mutation operation during the breeding process. Their proposed approach has two phases: The first phase focuses on produces feasible timetables, and the second phase will focus on improving the produced timetables. The two phases all utilize genetic algorithms to accomplish their tasks. The timetable representation used in this work is a 2D matrix where the rows are the time slots and the columns being the classes. The intersections of the rows and classes are where the teachers are placed in. Generation of the initial population involves creating a $m$-size population. The fittest individuals from that population are gathered to create the initial population. The fitness function used is dependent on which phase the fitness is being computed. In the first phase, the hard constraint cost of the timetable is used. On the other hand, the soft contraist cost is used during the second phase. During timetabling, the tuple of class and teacher are sorted based on the difficulty of scheduling the said tuple. This difficulty is determined by a set of low-level heuristics. Each tuple will be given a time slot that gives the tuple the least penalty as possible. The first phase will have this initial population of timetables be refined for a number of generations. During selection of parents for the next generation, a variation of the tournament selection. At the end of this phase, feasible timetables have already been generated. The last generation will now then be used by the second phase. Two mutations operations were used: (a) simple mutation, and (b) a hill-climber operator. The simple mutation simply swaps two random tuples in the same class. The second operator simply performs swaps two teachers and checks if the swapping improves the fitness of the timetable. If it does, then the swap is accepted. Otherwise, more swapping is performed until an improvement occurs. However, there is a limit to the number of times attempts at swapping is performed. This limit is set by a parameter. The experiments of the authors show that a feasible timetable is possible with the proposed method. The minimum hard constraint cost mustered by all the generated timetables is $0$ for both primary and high school, with the average hard constraint cost at $1.1$ and $2$, respectively. Only the high school timetable has soft constraint violations with the minimum cost at $2$ and the average cost at $2.67$. Unlike the previous two discussed works, the authors compared their approach to another previous work, specifically the approach of Beligiannis, G. N., Moschopoulos, G. P., Kaperonis, P., and Likothanassis, S. D. \cite{beligiannis-evolutionary-computation}. The minimum hard constraint cost of each approach is $0$. However, the minimum soft constraint cost of Raghavjee, R. and Pillay, N. is just $2$, compared to the cost of $6$ of the approach they are comparing against. Despite having better results than a previous work, it would have been more beneficial to compare their approach to other different approaches from previous works for us have better insights into the proposed approach \cite{raghavjee-ga-south-africa}.

Genetic algorithms may also be combined with another approach in producing timetables, just like how reinforcement learning was integrated into great deluge in a previously discussed work. Feng, X., Lee, Y., and Moon, I. formulated a new approach combines integer programming and genetic algorithms together to produce feasible university timetables \cite{feng-integer-prog-ga}. Feng, X., et. al. 

%
%
%
%
%
%
%
%
%